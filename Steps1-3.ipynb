{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66652fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679056d8",
   "metadata": {},
   "source": [
    "# Dataset 1: Job Placement Dataset\n",
    "Step 1\n",
    "Question: Can we predict if a student will be placed in a job based on work experience, specialization, and academics?\n",
    "Business Metric: Placement Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e754f7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Placement Prevalence: 68.84%\n",
      "Final Split Shapes (Train, Tune, Test):\n",
      "(150, 22) (32, 22) (33, 22)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load dataset\n",
    "df_job_raw = pd.read_csv('Placement_Data_Full_Class.csv')\n",
    "\n",
    "# 2. Step 2: Data Cleaning & Feature Engineering\n",
    "\n",
    "# DROP LEAKAGE AND IDENTIFIERS FIRST\n",
    "# We drop 'salary' here because it contains NaNs for all 'Not Placed' students.\n",
    "# Dropping it first ensures dropna() doesn't delete the 'Not Placed' records.\n",
    "df_job_reduced = df_job_raw.drop(columns=['salary', 'sl_no'], errors='ignore')\n",
    "\n",
    "# Now remove rows with missing values in the REMAINING columns\n",
    "df_job_cleaned = df_job_reduced.dropna().copy()\n",
    "\n",
    "# 3. Define categorical columns\n",
    "categorical_cols = [\n",
    "    'gender', 'ssc_b', 'hsc_b', 'hsc_s',\n",
    "    'degree_t', 'workex', 'specialisation', 'status'\n",
    "]\n",
    "\n",
    "# Convert types and simplify levels\n",
    "df_job_cleaned[categorical_cols] = df_job_cleaned[categorical_cols].astype('category')\n",
    "df_job_cleaned['specialisation'] = df_job_cleaned['specialisation'].apply(\n",
    "    lambda x: x if x in ['Mkt&HR', 'Mkt&Fin'] else 'Other'\n",
    ").astype('category')\n",
    "\n",
    "# 4. One-hot encoding\n",
    "df_job_encoded = pd.get_dummies(df_job_cleaned, columns=categorical_cols)\n",
    "\n",
    "# 5. Normalize numeric variables\n",
    "numeric_cols = list(df_job_encoded.select_dtypes('number'))\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_job_encoded[numeric_cols] = min_max_scaler.fit_transform(df_job_encoded[numeric_cols])\n",
    "\n",
    "# 6. Create target variable (1 for Placed, 0 for Not Placed)\n",
    "df_job_encoded['is_placed'] = df_job_encoded['status_Placed']\n",
    "\n",
    "# Drop the redundant status columns now that we have our target\n",
    "cols_to_drop = [\"status_Placed\", \"status_Not Placed\"]\n",
    "df_job_final = df_job_encoded.drop(columns=[c for c in cols_to_drop if c in df_job_encoded.columns])\n",
    "\n",
    "# 7. Calculate prevalence (Should now be ~68% instead of 100%)\n",
    "placement_prevalence = df_job_final[\"is_placed\"].mean()\n",
    "print(f\"Job Placement Prevalence: {placement_prevalence:.2%}\")\n",
    "\n",
    "# 8. Train / Tune / Test split\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_job_final,\n",
    "    train_size=0.7,\n",
    "    stratify=df_job_final.is_placed,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tune_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    train_size=0.5,\n",
    "    stratify=temp_df.is_placed,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Final Split Shapes (Train, Tune, Test):\")\n",
    "print(train_df.shape, tune_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ecfd7",
   "metadata": {},
   "source": [
    "# Step 3: Concerns\n",
    "Some concerns include potential bias from gender and academic background, salary dropped due to nulls and leakage risk, small dataset may cause overfitting, and placement depends on unobserved external factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9091f",
   "metadata": {},
   "source": [
    "# Dataset 2: College Completion Dataset\n",
    "Step 1\n",
    "Question: Can we predict if a college has above-median graduation rates?\n",
    "Business Metric: Graduation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "College Graduation Prevalence (Baseline): 45.68%\n",
      "College dataset shapes:\n",
      "Train: (2278, 86)\n",
      "Tune: (760, 86)\n",
      "Test: (760, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/l51l5jms4ws7zn1vkks87spr0000gn/T/ipykernel_89076/36344224.py:36: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = college.select_dtypes(include=[\"object\"]).columns\n"
     ]
    }
   ],
   "source": [
    "# 1. Load dataset\n",
    "df_college_raw = pd.read_csv(\"cc_institution_details.csv\")\n",
    "\n",
    "# 2. Target Creation & Initial Cleaning\n",
    "# Create binary target: 1 if above median, 0 otherwise\n",
    "grad_median_threshold = df_college_raw[\"grad_150_value\"].median()\n",
    "df_college_raw[\"is_high_grad\"] = (df_college_raw[\"grad_150_value\"] >= grad_median_threshold).astype(int)\n",
    "\n",
    "# Identify columns to drop (Leakage, IDs, and Irrelevant metadata)\n",
    "irrelevant_and_leakage_cols = [\n",
    "    \"index\", \"unitid\", \"chronname\", \"city\", \"site\", \"nicknames\",\n",
    "    \"similar\", \"counted_pct\", \"long_x\", \"lat_y\", \"grad_150_value\",\n",
    "    \"grad_100_value\", \"grad_100_percentile\", \"grad_150_percentile\",\n",
    "    \"vsa_year\", \"vsa_grad_after4_first\", \"vsa_grad_elsewhere_after4_first\",\n",
    "    \"vsa_enroll_after4_first\", \"vsa_enroll_elsewhere_after4_first\",\n",
    "    \"vsa_grad_after6_first\", \"vsa_grad_elsewhere_after6_first\",\n",
    "    \"vsa_enroll_after6_first\", \"vsa_enroll_elsewhere_after6_first\",\n",
    "    \"vsa_grad_after4_transfer\", \"vsa_grad_elsewhere_after4_transfer\",\n",
    "    \"vsa_enroll_after4_transfer\", \"vsa_enroll_elsewhere_after4_transfer\",\n",
    "    \"vsa_grad_after6_transfer\", \"vsa_grad_elsewhere_after6_transfer\",\n",
    "    \"vsa_enroll_after6_transfer\", \"vsa_enroll_elsewhere_after6_transfer\"\n",
    "]\n",
    "\n",
    "# Create a cleaned version by dropping defined columns\n",
    "df_college_cleaned = df_college_raw.drop(\n",
    "    columns=[c for c in irrelevant_and_leakage_cols if c in df_college_raw.columns]\n",
    ").copy()\n",
    "\n",
    "# 3. Handle Missing Values (Imputation)\n",
    "numeric_cols = df_college_cleaned.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_college_cleaned.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col != \"is_high_grad\":\n",
    "        df_college_cleaned[col] = df_college_cleaned[col].fillna(df_college_cleaned[col].median())\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_college_cleaned[col] = df_college_cleaned[col].fillna(df_college_cleaned[col].mode()[0])\n",
    "\n",
    "# 4. Feature Engineering: Collapse Carnegie Categories\n",
    "if \"basic\" in df_college_cleaned.columns:\n",
    "    def simplify_carnegie(category_name):\n",
    "        category_name = str(category_name).lower()\n",
    "        if \"research\" in category_name: return \"Research\"\n",
    "        if \"masters\" in category_name: return \"Masters\"\n",
    "        if \"baccalaureate\" in category_name: return \"Baccalaureate\"\n",
    "        if \"associate\" in category_name: return \"Associate\"\n",
    "        return \"Other\"\n",
    "\n",
    "    df_college_cleaned[\"basic_category\"] = df_college_cleaned[\"basic\"].apply(simplify_carnegie)\n",
    "    df_college_cleaned = df_college_cleaned.drop(columns=[\"basic\"])\n",
    "\n",
    "# Convert flags to integers\n",
    "if \"hbcu\" in df_college_cleaned.columns:\n",
    "    df_college_cleaned[\"is_hbcu\"] = (df_college_cleaned[\"hbcu\"] == \"X\").astype(int)\n",
    "    df_college_cleaned = df_college_cleaned.drop(columns=[\"hbcu\"])\n",
    "\n",
    "if \"flagship\" in df_college_cleaned.columns:\n",
    "    df_college_cleaned[\"is_flagship\"] = (df_college_cleaned[\"flagship\"] == \"X\").astype(int)\n",
    "    df_college_cleaned = df_college_cleaned.drop(columns=[\"flagship\"])\n",
    "\n",
    "# 5. Encoding & Scaling\n",
    "df_college_encoded = pd.get_dummies(df_college_cleaned, drop_first=True)\n",
    "\n",
    "# Standardize numeric features\n",
    "features_to_scale = [c for c in df_college_encoded.select_dtypes(include=[np.number]).columns if c != \"is_high_grad\"]\n",
    "standard_scaler = StandardScaler()\n",
    "df_college_encoded[features_to_scale] = standard_scaler.fit_transform(df_college_encoded[features_to_scale])\n",
    "\n",
    "# 6. Calculate prevalence\n",
    "college_grad_prevalence = df_college_encoded[\"is_high_grad\"].mean()\n",
    "print(f\"College Graduation Prevalence (Baseline): {college_grad_prevalence:.2%}\")\n",
    "\n",
    "# 7. Train / Tune / Test split\n",
    "train_college, temp_college = train_test_split(\n",
    "    df_college_encoded,\n",
    "    test_size=0.4,\n",
    "    stratify=df_college_encoded[\"is_high_grad\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tune_college, test_college = train_test_split(\n",
    "    temp_college,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_college[\"is_high_grad\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Final College Dataset Shapes:\")\n",
    "print(f\"Train: {train_college.shape}, Tune: {tune_college.shape}, Test: {test_college.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32535ea2",
   "metadata": {},
   "source": [
    "# Step 3: Concerns\n",
    "There could Possible bias between public vs private institutions, socioeconomic-related variables may influence results, graduation rates affected by external events (e.g., pandemic), and median split may oversimplify institutional performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
